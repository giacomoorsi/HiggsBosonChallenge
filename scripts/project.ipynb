{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from implementations import *\n",
    "from helper import *\n",
    "from feature_analysis import *\n",
    "from expansions import polynomial_expansion\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "def prepare_y_data(y,x, i_PRI=22) : \n",
    "    y_jet0  = y[x[:, i_PRI]==0]\n",
    "    y_jet1  = y[x[:, i_PRI] == 1]\n",
    "    y_jet2  = y[x[:, i_PRI] > 1]\n",
    "\n",
    "    y_jet0 = y_jet0.reshape((len(y_jet0), 1))\n",
    "    y_jet1 = y_jet1.reshape((len(y_jet1), 1))\n",
    "    y_jet2 = y_jet2.reshape((len(y_jet2), 1))\n",
    "\n",
    "    return y_jet0, y_jet1, y_jet2\n",
    "\n",
    "\n",
    "def prepare_x_data(x, i_PRI=22) : \n",
    "    tx_jet0 = x[x[:, i_PRI]==0]\n",
    "    tx_jet1 = x[x[:, i_PRI] == 1]\n",
    "    tx_jet2 = x[x[:, i_PRI] > 1]\n",
    "\n",
    "\n",
    "    tx_0_filtered = np.delete(tx_jet0, [4,5,6,12,22,23,24,25,26,27,28], axis=1)\n",
    "    tx_1_filtered = np.delete(tx_jet1, [4,5,6,12,22,26,27,28], axis=1)\n",
    "    tx_2_filtered = np.delete(tx_jet2, [22], axis=1)\n",
    "\n",
    "    tx_0_filtered = fix_nan_values(fix_missing_values(tx_0_filtered))\n",
    "    tx_1_filtered = fix_nan_values(fix_missing_values(tx_1_filtered))\n",
    "    tx_2_filtered = fix_nan_values(fix_missing_values(tx_2_filtered))\n",
    "\n",
    "    tx_0 = featureExpand(tx_0_filtered, 0)\n",
    "    tx_1 = featureExpand(tx_1_filtered, 1)\n",
    "    tx_2 = featureExpand(tx_2_filtered, 2)\n",
    "    return tx_0, tx_1, tx_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.DataFrame(tx_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_0, tx_train_1, tx_train_2 = prepare_x_data(tX)\n",
    "y_0, y_1, y_2 = prepare_y_data(y, tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic_regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_logistic_regression_model(y, tx, max_iter=20, gamma=0.05, k_fold=3) :\n",
    "    lambdas = np.logspace(-10, 4, 15)\n",
    "    degrees = np.arange(1, 20)\n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) : \n",
    "        expanded_tx = polynomial_expansion(tx, degree)\n",
    "       # print(expanded_tx.shape)\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "\n",
    "            results[i_degree, i_lambda] = cross_validate_logistic_regression(y, expanded_tx, max_iter, gamma, lambda_, k_fold)\n",
    "            print(\"degree={d},\\t lambda={l:e},\\taccuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_logistic_regression_model(y_0, tx_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from least_squares import cross_validate_least_squares \n",
    "\n",
    "def find_best_least_squares_model(y, tx, k_fold=5) :\n",
    "    lambdas = np.logspace(-10, 4, 15)\n",
    "    degrees = np.arange(1, 20)\n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) :\n",
    "        expanded_tx = polynomial_expansion(tx, degree)\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "            try : \n",
    "                results[i_degree, i_lambda] = cross_validate_least_squares(y, expanded_tx, lambda_, k_fold)\n",
    "                print(\"degree={d},\\t lambda={l:e},\\t accuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "            except np.linalg.LinAlgError : \n",
    "                results[i_degree, i_lambda] = 0\n",
    "                print(\"degree={d},\\t lambda={l:e},\\t accuracy={a}\".format(d=degree, l=lambda_, a=\"0 - singular matrix\"))\n",
    "\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_least_squares_model(y_2, tx_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(y, tx) : \n",
    "    degree_logistic, lambda_logistic, acc_logistic = find_best_logistic_regression_model(y, tx)\n",
    "    print(\"Logistic regression: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_logistic, l=lambda_logistic, a=acc_logistic))\n",
    "    degree_ls, lambda_ls, acc_ls = find_best_least_squares_model(y, tx)\n",
    "    print(\"Least squares: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_ls, l=lambda_ls, a=acc_ls))\n",
    "\n",
    "    if acc_logistic > acc_ls : \n",
    "        return \"logistic regression\", degree_logistic, lambda_logistic, acc_logistic\n",
    "    else : \n",
    "        return \"least squares\", degree_ls, lambda_ls, acc_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_for_higgs_dataset() : \n",
    "    \n",
    "    jet_0_model, jet_0_degree, jet_0_lambda, jet_0_accuracy = find_best_model(y_0, tx_train_0)\n",
    "    print(\"Jet0: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_0_model,d=jet_0_degree,l=jet_0_lambda,a=jet_0_accuracy))\n",
    "    jet_1_model, jet_1_degree, jet_1_lambda, jet_1_accuracy = find_best_model(y_1, tx_train_1)\n",
    "    print(\"Jet1: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_1_model,d=jet_1_degree,l=jet_1_lambda,a=jet_1_accuracy))\n",
    "    jet_2_model, jet_2_degree, jet_2_lambda, jet_2_accuracy = find_best_model(y_2, tx_train_2)\n",
    "    print(\"Jet2: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_2_model,d=jet_2_degree,l=jet_2_lambda,a=jet_2_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_model_for_higgs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 5,\n",
    "        \"lambda\" : 1e-3\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-6\n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 6,\n",
    "        \"lambda\" : 1e-4\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(models) : \n",
    "    weights = []\n",
    "    y = [y_0, y_1, y_2]  \n",
    "    tx = [tx_train_0, tx_train_1, tx_train_2]\n",
    "    for i, (jet, model) in enumerate(models.items()) : \n",
    "        x_expanded = polynomial_expansion(tx[i], model[\"degree\"])\n",
    "        if model[\"model\"] == \"least squares\" : \n",
    "            w, err = ridge_regression(y[i], x_expanded, model[\"lambda\"])\n",
    "            weights.append(w)\n",
    "        elif model[\"model\"] == \"logistic regression\" : \n",
    "            w = logistic_regression_penalized_gradient_descent(y[i], x_expanded, 0.01, model[\"lambda\"], 30)\n",
    "            weights.append(w)\n",
    "        else : \n",
    "            raise Exception(\"Model not recognised\")\n",
    "        print(\"weights computed for \", jet)\n",
    "            \n",
    "    return weights[0], weights[1], weights[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, x_test) : \n",
    "    i_PRI = 22\n",
    "    print(\"prepare dataset...\")\n",
    "    x_test_0, x_test_1, x_test_2 = prepare_x_data(x_test)\n",
    "    print(\"compute weights...\")\n",
    "    w_0, w_1, w_2 = compute_weights(models)\n",
    "    print(\"compute predictions...\")\n",
    "    x_test_0 = polynomial_expansion(x_test_0, models[\"jet0\"][\"degree\"])\n",
    "    x_test_1 = polynomial_expansion(x_test_1, models[\"jet1\"][\"degree\"])\n",
    "    x_test_2 = polynomial_expansion(x_test_2, models[\"jet2\"][\"degree\"])\n",
    "\n",
    "    y_0 = predict_labels(w_0, x_test_0)\n",
    "    y_1 = predict_labels(w_1, x_test_1)\n",
    "    y_2 = predict_labels(w_2, x_test_2)\n",
    "\n",
    "    y_pred = np.zeros((len(x_test), 1))\n",
    "    y_pred[x_test[:, i_PRI]==0] = y_0\n",
    "    y_pred[x_test[:, i_PRI]==1] = y_1\n",
    "    y_pred[x_test[:, i_PRI]>=2] = y_2\n",
    "\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH=\"out2.csv\"\n",
    "y_pred = predict(models, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "047d5c4a70aa4e5ae964d8b25b83a0a6056fc4ba4dd2c3a708bdfa354f913a43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
