{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from implementations import *\n",
    "from helper import *\n",
    "from feature_analysis import *\n",
    "from expansions import polynomial_expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "i_PRI = 22\n",
    "y_jet0  = y[tX[:, i_PRI]==0]\n",
    "tx_jet0 = tX[tX[:, i_PRI]==0]\n",
    "\n",
    "y_jet1  = y[ tX[:, i_PRI] == 1]\n",
    "tx_jet1 = tX[tX[:, i_PRI] == 1]\n",
    "\n",
    "y_jet2  = y[ tX[:, i_PRI] > 1]\n",
    "tx_jet2 = tX[tX[:, i_PRI] > 1]\n",
    "#----------------------------------\n",
    "#Then it can be executed like this\n",
    "tx_0_filtered = np.delete(tx_jet0, [4,5,6,12,22,23,24,25,26,27,28], axis=1)\n",
    "tx_1_filtered = np.delete(tx_jet1, [4,5,6,12,22,26,27,28], axis=1)\n",
    "tx_2_filtered = np.delete(tx_jet2, [22], axis=1)\n",
    "\n",
    "tx_0_filtered = fix_nan_values(fix_missing_values(tx_0_filtered))\n",
    "tx_1_filtered = fix_nan_values(fix_missing_values(tx_1_filtered))\n",
    "tx_2_filtered = fix_nan_values(fix_missing_values(tx_2_filtered))\n",
    "\n",
    "tx_train_0 = featureExpand(tx_0_filtered, 0)\n",
    "tx_train_1 = featureExpand(tx_1_filtered, 1)\n",
    "tx_train_2 = featureExpand(tx_2_filtered, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_jet0 = y_jet0.reshape((len(y_jet0), 1))\n",
    "y_jet1 = y_jet1.reshape((len(y_jet1), 1))\n",
    "y_jet2 = y_jet2.reshape((len(y_jet2), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic_regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_logistic_regression_model(y, tx, max_iter=10, gamma=0.01, k_fold=4) :\n",
    "   # lambdas = np.logspace(0, -10, 11)\n",
    "    #lambdas = np.logspace(0, -20, 4)\n",
    "    lambdas = [100, 1, 1e-5, 0]\n",
    "    degrees = np.arange(1, 5) \n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) : \n",
    "        tx = polynomial_expansion(tx, degree)\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "\n",
    "            results[i_degree, i_lambda] = cross_validate_logistic_regression(y, tx, max_iter, gamma, lambda_, k_fold)\n",
    "            print(\"degree={d},\\t lambda={l},\\taccuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=1,\t lambda=100,\taccuracy=0.7448654816238289\n",
      "degree=1,\t lambda=1,\taccuracy=0.7448654816238289\n",
      "degree=1,\t lambda=1e-05,\taccuracy=0.7448654816238289\n",
      "degree=1,\t lambda=0,\taccuracy=0.7448654816238289\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-24-ce958adb2fc2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfind_best_logistic_regression_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_jet0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx_0_filtered\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-23-4fa3b68141a5>\u001B[0m in \u001B[0;36mfind_best_logistic_regression_model\u001B[1;34m(y, tx, max_iter, gamma, k_fold)\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi_lambda\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlambda_\u001B[0m  \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlambdas\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m             \u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi_degree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi_lambda\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcross_validate_logistic_regression\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_iter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlambda_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk_fold\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"degree={d},\\t lambda={l},\\taccuracy={a}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdegree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ml\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlambda_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi_degree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi_lambda\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\EPFL\\CS-433 ML\\ml-project-1-novae\\scripts\\logistic_regression.py\u001B[0m in \u001B[0;36mcross_validate_logistic_regression\u001B[1;34m(y, tx, max_iter, gamma, lambda_, k_fold)\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtest_indices\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 95\u001B[1;33m         \u001B[0mw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlogistic_regression_penalized_gradient_descent\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlambda_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_iter\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     96\u001B[0m         \u001B[0mclassified\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredict_labels\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx_test\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m         \u001B[0mclassifications\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassified\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\EPFL\\CS-433 ML\\ml-project-1-novae\\scripts\\logistic_regression.py\u001B[0m in \u001B[0;36mlogistic_regression_penalized_gradient_descent\u001B[1;34m(y, tx, gamma, lambda_, max_iter)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_iter\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlearning_by_penalized_gradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlambda_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m         \u001B[0mlosses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlosses\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlosses\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlosses\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mthreshold\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\EPFL\\CS-433 ML\\ml-project-1-novae\\scripts\\logistic_regression.py\u001B[0m in \u001B[0;36mlearning_by_penalized_gradient\u001B[1;34m(y, tx, w, gamma, lambda_)\u001B[0m\n\u001B[0;32m     57\u001B[0m     \u001B[0mReturn\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mloss\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mupdated\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \"\"\"\n\u001B[1;32m---> 59\u001B[1;33m     \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpenalized_logistic_regression\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlambda_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m     \u001B[0mupdated_w\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mw\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mgamma\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mgrad\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mupdated_w\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\EPFL\\CS-433 ML\\ml-project-1-novae\\scripts\\logistic_regression.py\u001B[0m in \u001B[0;36mpenalized_logistic_regression\u001B[1;34m(y, tx, w, lambda_)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpenalized_logistic_regression\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlambda_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m     \u001B[1;34m\"\"\"return the loss, gradient\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m     \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcalculate_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mlambda_\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m     \u001B[0mgradient\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcalculate_gradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m2\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlambda_\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "find_best_logistic_regression_model(y_jet0, tx_0_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from least_squares import cross_validate_least_squares \n",
    "\n",
    "def find_best_least_squares_model(y, tx, k_fold=4) :\n",
    "   # lambdas = np.logspace(0, -10, 11)\n",
    "    #lambdas = np.logspace(0, -20, 4)\n",
    "    lambdas = [100, 1, 1e-5, 0]\n",
    "    degrees = np.arange(1, 5) \n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) : \n",
    "        tx = polynomial_expansion(tx, degree)\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "            try : \n",
    "                results[i_degree, i_lambda] = cross_validate_least_squares(y, tx, lambda_, k_fold)\n",
    "                print(\"degree={d},\\t lambda={l},\\t accuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "            except np.linalg.LinAlgError : \n",
    "                results[i_degree, i_lambda] = 0\n",
    "                print(\"degree={d},\\t lambda={l},\\t accuracy={a}\".format(d=degree, l=lambda_, a=\"0 - singular matrix\"))\n",
    "\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_least_squares_model(y_jet0, tx_0_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(y, tx) : \n",
    "    degree_logistic, lambda_logistic, acc_logistic = find_best_logistic_regression_model(y, tx, max_iter=10, gamma=0.01, k_fold=4)\n",
    "    print(\"Logistic regression: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_logistic, l=lambda_logistic, a=acc_logistic))\n",
    "    degree_ls, lambda_ls, acc_ls = find_best_least_squares_model(y, tx, k_fold=4)\n",
    "    print(\"Least squares: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_ls, l=lambda_ls, a=acc_ls))\n",
    "\n",
    "    if acc_logistic > acc_ls : \n",
    "        return \"logistic regression\", degree_logistic, lambda_logistic, acc_logistic\n",
    "    else : \n",
    "        return \"least squares\", degree_ls, lambda_ls, acc_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_for_higgs_dataset(y,tx) : \n",
    "    \n",
    "    jet_0_model, jet_0_degree, jet_0_lambda, jet_0_accuracy = find_best_model(y_jet0, tx_0_filtered)\n",
    "    print(\"Jet0: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_0_model,d=jet_0_degree,l=jet_0_lambda,a=jet_0_accuracy))\n",
    "    jet_1_model, jet_1_degree, jet_1_lambda, jet_1_accuracy = find_best_model(y_jet1, tx_1_filtered)\n",
    "    print(\"Jet1: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_1_model,d=jet_1_degree,l=jet_1_lambda,a=jet_1_accuracy))\n",
    "    jet_2_model, jet_2_degree, jet_2_lambda, jet_2_accuracy = find_best_model(y_jet2, tx_2_filtered)\n",
    "    print(\"Jet2: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_2_model,d=jet_2_degree,l=jet_2_lambda,a=jet_2_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "047d5c4a70aa4e5ae964d8b25b83a0a6056fc4ba4dd2c3a708bdfa354f913a43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}