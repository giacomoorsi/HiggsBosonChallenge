{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from implementations import *\n",
    "from helper import *\n",
    "from feature_analysis import *\n",
    "from expansions import polynomial_expansion\n",
    "import seaborn as sns\n",
    "import pandas as pd #temporary\n",
    "from logistic_regression import *\n",
    "import disk_helpers\n",
    "\n",
    "from proj1_helpers import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(x, means, stds, medians) : \n",
    "    i_PRI = 22\n",
    "    \n",
    "    x = fix_missing_values(x)\n",
    "\n",
    "    tx_jet0 = x[x[:, i_PRI] == 0]\n",
    "    tx_jet1 = x[x[:, i_PRI] == 1]\n",
    "    tx_jet2 = x[x[:, i_PRI] > 1]\n",
    "\n",
    "\n",
    "    tx_0_filtered = np.delete(tx_jet0, [4,5,6,12,22,23,24,25,26,27,28], axis=1)\n",
    "    tx_1_filtered = np.delete(tx_jet1, [4,5,6,12,22,26,27,28], axis=1)\n",
    "    tx_2_filtered = np.delete(tx_jet2, [22], axis=1)\n",
    "\n",
    "    # Replace missing values (and outliers) with median values\n",
    "    tx_0_filtered = fix_nan_values(tx_0_filtered, medians[0])\n",
    "    tx_1_filtered = fix_nan_values(tx_1_filtered, medians[1])\n",
    "    tx_2_filtered = fix_nan_values(tx_2_filtered, medians[2])\n",
    "\n",
    "\n",
    "    # Feature engineering\n",
    "    tx_0 = featureExpand(tx_0_filtered, 0)\n",
    "    tx_1 = featureExpand(tx_1_filtered, 1)\n",
    "    tx_2 = featureExpand(tx_2_filtered, 2)\n",
    "\n",
    "    ### TO DO : check\n",
    "    # Remove columns with standard deviation == 0 (all the values are the same!)\n",
    "    tx_0 = np.delete(tx_0, [0, 12, 18], axis=1)\n",
    "    tx_1 = np.delete(tx_1,[0], axis=1)\n",
    "\n",
    "    tx_2 = np.delete(tx_2,[0], axis=1)\n",
    "\n",
    "    \n",
    "    ### END TO DO \n",
    "    \n",
    "    # Compute standardization\n",
    "    tx_0 = standardize(tx_0, means[0], stds[0])\n",
    "    tx_1 = standardize(tx_1, means[1], stds[1])\n",
    "    tx_2 = standardize(tx_2, means[2], stds[2])\n",
    "    return tx_0, tx_1, tx_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_y_data(y,x, i_PRI=22) : \n",
    "    y_jet0  = y[x[:, i_PRI]==0]\n",
    "    y_jet1  = y[x[:, i_PRI] == 1]\n",
    "    y_jet2  = y[x[:, i_PRI] > 1]\n",
    "\n",
    "    y_jet0 = y_jet0.reshape((len(y_jet0), 1))\n",
    "    y_jet1 = y_jet1.reshape((len(y_jet1), 1))\n",
    "    y_jet2 = y_jet2.reshape((len(y_jet2), 1))\n",
    "\n",
    "    return y_jet0, y_jet1, y_jet2\n",
    "\n",
    "\n",
    "def prepare_train_data(x, i_PRI=22) : \n",
    "    # Replace missing values (-999) with NaN\n",
    "    x = fix_missing_values(x)\n",
    "    \n",
    "    tx_jet0 = x[x[:, i_PRI] ==0]\n",
    "    tx_jet1 = x[x[:, i_PRI] == 1]\n",
    "    tx_jet2 = x[x[:, i_PRI] > 1]\n",
    "\n",
    "\n",
    "    tx_0_filtered = np.delete(tx_jet0, [4,5,6,12,22,23,24,25,26,27,28], axis=1)\n",
    "    tx_1_filtered = np.delete(tx_jet1, [4,5,6,12,22,26,27,28], axis=1)\n",
    "    tx_2_filtered = np.delete(tx_jet2, [22], axis=1)\n",
    "\n",
    "   \n",
    "    # Treat outliers as missing values (replace with NaN)\n",
    "    tx_0_filtered = identify_outliers(tx_0_filtered)\n",
    "    tx_1_filtered = identify_outliers(tx_1_filtered)\n",
    "    tx_2_filtered = identify_outliers(tx_2_filtered)\n",
    "\n",
    "    # Compute medians\n",
    "    medians = []\n",
    "    medians.append(np.nanmedian(tx_0_filtered, axis=0))\n",
    "    medians.append(np.nanmedian(tx_1_filtered, axis=0))\n",
    "    medians.append(np.nanmedian(tx_2_filtered, axis=0))\n",
    "    \n",
    "\n",
    "    # Replace missing values (and outliers) with median values\n",
    "    tx_0_filtered = fix_nan_values(tx_0_filtered, medians[0])\n",
    "    tx_1_filtered = fix_nan_values(tx_1_filtered, medians[1])\n",
    "    tx_2_filtered = fix_nan_values(tx_2_filtered, medians[2])\n",
    "\n",
    "    tx_0 = featureExpand(tx_0_filtered, 0)\n",
    "    tx_1 = featureExpand(tx_1_filtered, 1)\n",
    "    tx_2 = featureExpand(tx_2_filtered, 2)\n",
    "\n",
    "    stds = []\n",
    "    stds.append(np.std(tx_0, axis=0))\n",
    "    stds.append(np.std(tx_1, axis=0))\n",
    "    stds.append(np.std(tx_2, axis=0))\n",
    "\n",
    "   \n",
    "\n",
    "    ### TO DO : check\n",
    "    # Remove columns with standard deviation == 0 (all the values are the same!)\n",
    "    print(\"tx_0, colonne nulle: \", np.where(stds[0]==0))\n",
    "    print(\"tx_1, colonne nulle: \", np.where(stds[1]==0))\n",
    "    print(\"tx_2, colonne nulle: \", np.where(stds[2]==0))\n",
    "    tx_0, stds[0] = remove_useless_columns(tx_0, stds[0])\n",
    "    tx_1, stds[1] = remove_useless_columns(tx_1, stds[1])\n",
    "    tx_2, stds[2] = remove_useless_columns(tx_2, stds[2])\n",
    "    \n",
    "\n",
    "    ### END TO DO \n",
    "\n",
    "    # Compute means and standard deviations for standardization\n",
    "    means = []\n",
    "    means.append(np.mean(tx_0, axis=0))\n",
    "    means.append(np.mean(tx_1, axis=0))\n",
    "    means.append(np.mean(tx_2, axis=0))\n",
    "\n",
    "    # Compute standardization\n",
    "    tx_0 = standardize(tx_0, means[0], stds[0])\n",
    "    tx_1 = standardize(tx_1, means[1], stds[1])\n",
    "    tx_2 = standardize(tx_2, means[2], stds[2])\n",
    "    \n",
    "    return tx_0, tx_1, tx_2, means, stds, medians\n",
    "\n",
    "# def remove_outliers(y, tx, keep=0.95) : \n",
    "#     values_to_be_deleted = np.zeros(tx.shape[0]) # At first we keep all\n",
    "#     for column in range(tx.shape[1]) : \n",
    "#         min_value = np.quantile(tx[:, column],(1-keep)/2)\n",
    "#         max_value = np.quantile(tx[:, column],(1+keep)/2)\n",
    "#         values_to_be_deleted = np.logical_or(values_to_be_deleted, np.logical_or(tx[:, column]<min_value, tx[:, column]>max_value))\n",
    "    \n",
    "#     values_to_be_kept = np.logical_not(values_to_be_deleted)\n",
    "#     return y[values_to_be_kept, :], tx[values_to_be_kept, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_0, tx_train_1, tx_train_2, means, stds, medians = prepare_train_data(tX)\n",
    "y_0, y_1, y_2 = prepare_y_data(y, tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.DataFrame(tx_train_0)\n",
    "for column in db : \n",
    "    plt.figure()\n",
    "    db.boxplot([column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_logistic_regression_model(y, tx, max_iter=100, gamma=0.05, k_fold=3) :\n",
    "    \"\"\"Computes the best logistic regression model for the given `y` and `tx`\"\"\"\n",
    "\n",
    "    lambdas = np.logspace(-10, 4, 15)\n",
    "    degrees = np.arange(1, 7)\n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) : \n",
    "        expanded_tx = polynomial_expansion(tx, degree)\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "            results[i_degree, i_lambda] = cross_validate_logistic_regression(y, expanded_tx, max_iter, gamma, lambda_, k_fold)\n",
    "            print(\"degree={d},\\t lambda={l:e},\\taccuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "\n",
    "    disk_helpers.save_data('logistic-regression', degrees, lambdas, results)\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_logistic_regression_model(y_0, tx_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-20, -9, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from least_squares import cross_validate_least_squares\n",
    "from plots import plot_degree_errors_plt\n",
    "\n",
    "\n",
    "def find_best_least_squares_model(y, tx, jet_string, k_fold=4) :\n",
    "    \"\"\"Computes the best least squares model for the given `y` and `tx`\"\"\"\n",
    "    lambdas = np.logspace(-20, 0, 21)\n",
    "\n",
    "    degrees = np.arange(4, 5)\n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) :\n",
    "        print(\"build expanded...\")\n",
    "        expanded_tx = polynomial_expansion(tx, degree, mixed_columns=True)\n",
    "        print(\"build model...\")\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "            try : \n",
    "                results[i_degree, i_lambda] = cross_validate_least_squares(y, expanded_tx, lambda_, k_fold)\n",
    "                print(\"degree={d},\\t lambda={l:e},\\t accuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "            except np.linalg.LinAlgError : \n",
    "                results[i_degree, i_lambda] = 0\n",
    "                print(\"degree={d},\\t lambda={l:e},\\t accuracy={a}\".format(d=degree, l=lambda_, a=\"0 - singular matrix\"))\n",
    "\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "    disk_helpers.save_data('least-squares', jet_string, degrees, lambdas, results)\n",
    "    plot_degree_errors_plt(degrees, lambdas, results)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#find_best_least_squares_model(y_0, tx_train_0, 'jet0')\n",
    "#find_best_least_squares_model(y_1, tx_train_1, 'jet1')\n",
    "find_best_least_squares_model(y_2, tx_train_2, 'jet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(y, tx) : \n",
    "    \"\"\"Finds the best model for the given `y` and `tx`\"\"\"\n",
    "    degree_logistic, lambda_logistic, acc_logistic = find_best_logistic_regression_model(y, tx)\n",
    "    print(\"Logistic regression: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_logistic, l=lambda_logistic, a=acc_logistic))\n",
    "    degree_ls, lambda_ls, acc_ls = find_best_least_squares_model(y, tx)\n",
    "    print(\"Least squares: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_ls, l=lambda_ls, a=acc_ls))\n",
    "\n",
    "    if acc_logistic > acc_ls : \n",
    "        return \"logistic regression\", degree_logistic, lambda_logistic, acc_logistic\n",
    "    else : \n",
    "        return \"least squares\", degree_ls, lambda_ls, acc_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_for_higgs_dataset() : \n",
    "    \"\"\"Finds the best model for the entire train dataset\"\"\"\n",
    "    \n",
    "    jet_0_model, jet_0_degree, jet_0_lambda, jet_0_accuracy = find_best_model(y_0, tx_train_0)\n",
    "    print(\"Jet0: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_0_model,d=jet_0_degree,l=jet_0_lambda,a=jet_0_accuracy))\n",
    "    jet_1_model, jet_1_degree, jet_1_lambda, jet_1_accuracy = find_best_model(y_1, tx_train_1)\n",
    "    print(\"Jet1: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_1_model,d=jet_1_degree,l=jet_1_lambda,a=jet_1_accuracy))\n",
    "    jet_2_model, jet_2_degree, jet_2_lambda, jet_2_accuracy = find_best_model(y_2, tx_train_2)\n",
    "    print(\"Jet2: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_2_model,d=jet_2_degree,l=jet_2_lambda,a=jet_2_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_model_for_higgs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 5,\n",
    "        \"lambda\" : 1e-3,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-6,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.7976 # tx not mixed\n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 6,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0\n",
    "    }\n",
    "}\n",
    "\n",
    "models_new = {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 3,\n",
    "        \"lambda\" : 0.1,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8355219697727956\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-5,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8043203507866906  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 5,\n",
    "        \"lambda\" : 0.001,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8258478081058727 \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "models_0_for_Nans = {\n",
    " \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 3,\n",
    "        \"lambda\" : 1e-3,\n",
    "        \"mixed\" : True,\n",
    "        \"accuracy\" : 0.8473246753246754\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 4,\n",
    "        \"lambda\" : 10000,\n",
    "        \"mixed\" : True,\n",
    "        \"accuracy\" : 0.79718  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 2,\n",
    "        \"lambda\" : 0.01,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8307976908110867 \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "models_oggi = {\n",
    " \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-5,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8473246753246754\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.79718  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8307976908110867 \n",
    "    }\n",
    "}\n",
    "\n",
    "models_statistics_31oct_15 =  {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 4,\n",
    "        \"lambda\" : 1e-10,\n",
    "        \"mixed\" : True,\n",
    "        \"accuracy\" : 0.8470\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 6,\n",
    "        \"lambda\" : 1e-3,\n",
    "        \"mixed\" :  True,\n",
    "        \"accuracy\" : 0.8069  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 4,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : True,\n",
    "        \"accuracy\" : 0.8342 \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(models) : \n",
    "    \"\"\"Computes the weights for the given models\"\"\"\n",
    "    weights = []\n",
    "    y = [y_0, y_1, y_2]  \n",
    "    tx = [tx_train_0, tx_train_1, tx_train_2]\n",
    "    for i, (jet, model) in enumerate(models.items()) : \n",
    "        print(\"jet\", i, \", degree: \", model[\"degree\"], \"lambda: \", model[\"lambda\"], \"expansion: \", model[\"mixed\"])\n",
    "        x_expanded = polynomial_expansion(tx[i], model[\"degree\"], mixed_columns=model[\"mixed\"])\n",
    "        print(\"build model for jet\", i)\n",
    "\n",
    "        if model[\"model\"] == \"least squares\" : \n",
    "            w, err = ridge_regression(y[i], x_expanded, model[\"lambda\"])\n",
    "            weights.append(w)\n",
    "        elif model[\"model\"] == \"logistic regression\" : \n",
    "            w = logistic_regression_penalized_gradient_descent(y[i], x_expanded, 0.01, model[\"lambda\"], 30)\n",
    "            weights.append(w)\n",
    "        else : \n",
    "            raise Exception(\"Model not recognised\")\n",
    "        print(\"weights computed for\", jet)\n",
    "            \n",
    "    return weights[0], weights[1], weights[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, x_test) : \n",
    "    \"\"\"Makes the prediction given the models chosen and the test dataset\"\"\"\n",
    "    i_PRI = 22\n",
    "    print(\"prepare dataset...\")\n",
    "    x_test_0, x_test_1, x_test_2 = prepare_test_data(x_test, means, stds, medians)\n",
    "    print(\"compute weights...\")\n",
    "    w_0, w_1, w_2 = compute_weights(models)\n",
    "    \n",
    "    print(\"build matrices for predictions 0 ...\")\n",
    "    x_1 = polynomial_expansion(x_test_0, models[\"jet0\"][\"degree\"], mixed_columns=models[\"jet0\"][\"mixed\"])\n",
    "    print(\"build matrices for predictions 1 ...\")\n",
    "    x_2 = polynomial_expansion(x_test_1, models[\"jet1\"][\"degree\"], mixed_columns=models[\"jet1\"][\"mixed\"])\n",
    "    print(\"build matrices for predictions 2 ...\")\n",
    "    x_3 = polynomial_expansion(x_test_2, models[\"jet2\"][\"degree\"], mixed_columns=models[\"jet2\"][\"mixed\"])\n",
    "\n",
    "    print(\"compute predictions...\")\n",
    "\n",
    "    y_0_predicted = predict_labels(w_0, x_1)\n",
    "    y_1_predicted = predict_labels(w_1, x_2)\n",
    "    y_2_predicted = predict_labels(w_2, x_3)\n",
    "\n",
    "    y_pred = np.zeros((len(x_test), 1))\n",
    "    y_pred[x_test[:, i_PRI]==0] = y_0_predicted\n",
    "    y_pred[x_test[:, i_PRI]==1] = y_1_predicted\n",
    "    y_pred[x_test[:, i_PRI]>=2] = y_2_predicted\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH=\"out12.csv\"\n",
    "y_pred = predict(models_statistics_31oct_15, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation\n",
    "We can estimate the accuracy of our model on the test dataset without uploading data su AIcrowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(models) : \n",
    "    \"\"\" Estimates the accuracy of our model on the test dataset without uploading to AIcrowd \"\"\"\n",
    "    i_PRI = 22\n",
    "    n_0 = sum(tX_test[:, i_PRI]==0)\n",
    "    n_1 = sum(tX_test[:, i_PRI]==1)\n",
    "    n_2 = sum(tX_test[:, i_PRI]>=2)\n",
    "\n",
    "    accuracy = (n_0*models[\"jet0\"][\"accuracy\"] + n_1*models[\"jet1\"][\"accuracy\"] + n_2*models[\"jet2\"][\"accuracy\"])/(len(tX_test))\n",
    "\n",
    "    print(\"The estimate accuracy with the given model is\", round(accuracy, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation(models_statistics_31oct_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "047d5c4a70aa4e5ae964d8b25b83a0a6056fc4ba4dd2c3a708bdfa354f913a43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
