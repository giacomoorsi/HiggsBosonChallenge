{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_processing import prepare_train_data\n",
    "from expansions import polynomial_expansion\n",
    "from logistic_regression import cross_validate_logistic_regression\n",
    "from least_squares import cross_validate_least_squares\n",
    "from plots import plot_degree_errors_plt\n",
    "\n",
    "\n",
    "import disk_helpers\n",
    "\n",
    "from proj1_helpers import *\n",
    "\n",
    "JET_COLUMN = 22 # the column which we use to divide the dataset in sub-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, tX, _ = load_csv_data(DATA_TRAIN_PATH)\n",
    "y_jets, x_jets, replacing_values, means, stds = prepare_train_data(y, tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_best_logistic_regression_model` and `find_best_least_squares_model` let us find the best model given `y` and `tx`.   \n",
    "It is possible to change `lambdas` and `degrees` in the procedure definition to set the interval of training of the hyperparameters.   \n",
    "\n",
    "A cross-validation with `k-fold` folds will be executed. The results will be saved on the disk and a graph will be plotted at the end of the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_logistic_regression_model(y, tx, jet_string, max_iter=100, gamma=0.05, k_fold=3) :\n",
    "    \"\"\"Computes the best logistic regression model for the given `y` and `tx`\"\"\"\n",
    "\n",
    "    lambdas = np.logspace(-10, 4, 15)\n",
    "    degrees = np.arange(1, 7)\n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) : \n",
    "        expanded_tx = polynomial_expansion(tx, degree)\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "            results[i_degree, i_lambda] = cross_validate_logistic_regression(y, expanded_tx, max_iter, gamma, lambda_, k_fold)\n",
    "            print(\"degree={d},\\t lambda={l:e},\\taccuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "\n",
    "    disk_helpers.save_data('logistic-regression', jet_string, degrees, lambdas, results)\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_logistic_regression_model(y_jets[0], x_jets[0], 'jet0')\n",
    "find_best_logistic_regression_model(y_jets[1], x_jets[1], 'jet1')\n",
    "find_best_logistic_regression_model(y_jets[2], x_jets[2], 'jet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_least_squares_model(y, tx, jet_string, k_fold=4) :\n",
    "    \"\"\"Computes the best least squares model for the given `y` and `tx`\"\"\"\n",
    "    lambdas = np.logspace(-20, 3, 24)\n",
    "\n",
    "    degrees = np.arange(1, 10)\n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) :\n",
    "        expanded_tx = polynomial_expansion(tx, degree, mixed_columns=True)\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "            try : \n",
    "                results[i_degree, i_lambda] = cross_validate_least_squares(y, expanded_tx, lambda_, k_fold)\n",
    "                print(\"degree={d},\\t lambda={l:e},\\t accuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "            except np.linalg.LinAlgError : \n",
    "                results[i_degree, i_lambda] = 0\n",
    "                print(\"degree={d},\\t lambda={l:e},\\t accuracy={a}\".format(d=degree, l=lambda_, a=\"0 - singular matrix\"))\n",
    "\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "    disk_helpers.save_data('least-squares', jet_string, degrees, lambdas, results)\n",
    "    plot_degree_errors_plt(degrees, lambdas, results)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_least_squares_model(y_jets[0], x_jets[0], 'jet0')\n",
    "find_best_least_squares_model(y_jets[1], x_jets[1], 'jet1')\n",
    "find_best_least_squares_model(y_jets[2], x_jets[2], 'jet2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train every subset of the train dataset (divided by the column `jet`) it is possible to run `find_model_for_higgs_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(y, tx) : \n",
    "    \"\"\"Finds the best model for the given `y` and `tx`\"\"\"\n",
    "    degree_logistic, lambda_logistic, acc_logistic = find_best_logistic_regression_model(y, tx)\n",
    "    print(\"Logistic regression: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_logistic, l=lambda_logistic, a=acc_logistic))\n",
    "    degree_ls, lambda_ls, acc_ls = find_best_least_squares_model(y, tx)\n",
    "    print(\"Least squares: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_ls, l=lambda_ls, a=acc_ls))\n",
    "\n",
    "    if acc_logistic > acc_ls : \n",
    "        return \"logistic regression\", degree_logistic, lambda_logistic, acc_logistic\n",
    "    else : \n",
    "        return \"least squares\", degree_ls, lambda_ls, acc_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_for_higgs_dataset() : \n",
    "    \"\"\"Finds the best model for the entire train dataset\"\"\"\n",
    "    \n",
    "    jet_0_model, jet_0_degree, jet_0_lambda, jet_0_accuracy = find_best_model(y_jets[0], x_jets[0])\n",
    "    print(\"Jet0: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_0_model,d=jet_0_degree,l=jet_0_lambda,a=jet_0_accuracy))\n",
    "    jet_1_model, jet_1_degree, jet_1_lambda, jet_1_accuracy = find_best_model(y_jets[1], x_jets[1])\n",
    "    print(\"Jet1: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_1_model,d=jet_1_degree,l=jet_1_lambda,a=jet_1_accuracy))\n",
    "    jet_2_model, jet_2_degree, jet_2_lambda, jet_2_accuracy = find_best_model(y_jets[2], x_jets[2])\n",
    "    print(\"Jet2: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_2_model,d=jet_2_degree,l=jet_2_lambda,a=jet_2_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_model_for_higgs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we generate a prediction on the test dataset given a model.   \n",
    "A model is a dictionary like the ones shown below in which it is specified the model and the hyper-parameters to be used in each subset of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 5,\n",
    "        \"lambda\" : 1e-3,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-6,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.7976 # tx not mixed\n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 6,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0\n",
    "    }\n",
    "}\n",
    "\n",
    "models_new = {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 3,\n",
    "        \"lambda\" : 0.1,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8355219697727956\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-5,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8043203507866906  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 5,\n",
    "        \"lambda\" : 0.001,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8258478081058727 \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "models_0_for_Nans = {\n",
    " \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 3,\n",
    "        \"lambda\" : 1e-3,\n",
    "        \"mixed\" : True,\n",
    "        \"accuracy\" : 0.8473246753246754\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 4,\n",
    "        \"lambda\" : 10000,\n",
    "        \"mixed\" : True,\n",
    "        \"accuracy\" : 0.79718  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 2,\n",
    "        \"lambda\" : 0.01,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8307976908110867 \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "models_oggi = {\n",
    " \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-5,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8473246753246754\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.79718  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8307976908110867 \n",
    "    }\n",
    "}\n",
    "\n",
    "models_statistics_31oct_15 =  {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 4,\n",
    "        \"lambda\" : 1e-10,\n",
    "        \"mixed\" : True,\n",
    "        \"accuracy\" : 0.8470\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 6,\n",
    "        \"lambda\" : 1e-3,\n",
    "        \"mixed\" :  True,\n",
    "        \"accuracy\" : 0.8069  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 4,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : True,\n",
    "        \"accuracy\" : 0.8342 \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_weights(models) : \n",
    "    \"\"\"Computes the weights for the given models\"\"\"\n",
    "    weights = []\n",
    "    y = [y_0, y_1, y_2]  \n",
    "    tx = [tx_train_0, tx_train_1, tx_train_2]\n",
    "    for i, (jet, model) in enumerate(models.items()) : \n",
    "        print(\"jet\", i, \", degree: \", model[\"degree\"], \"lambda: \", model[\"lambda\"], \"expansion: \", model[\"mixed\"])\n",
    "        x_expanded = polynomial_expansion(tx[i], model[\"degree\"], mixed_columns=model[\"mixed\"])\n",
    "        print(\"build model for jet\", i)\n",
    "\n",
    "        if model[\"model\"] == \"least squares\" : \n",
    "            w, err = ridge_regression(y[i], x_expanded, model[\"lambda\"])\n",
    "            weights.append(w)\n",
    "        elif model[\"model\"] == \"logistic regression\" : \n",
    "            w = logistic_regression_penalized_gradient_descent(y[i], x_expanded, 0.01, model[\"lambda\"], 30)\n",
    "            weights.append(w)\n",
    "        else : \n",
    "            raise Exception(\"Model not recognised\")\n",
    "        print(\"weights computed for\", jet)\n",
    "            \n",
    "    return weights[0], weights[1], weights[2]\n",
    "def predict(models, x_test) : \n",
    "    \"\"\"Makes the prediction given the models chosen and the test dataset\"\"\"\n",
    "    i_PRI = 22\n",
    "    print(\"prepare dataset...\")\n",
    "    x_test_0, x_test_1, x_test_2 = prepare_test_data(x_test, means, stds, medians)\n",
    "    print(\"compute weights...\")\n",
    "    w_0, w_1, w_2 = compute_weights(models)\n",
    "    \n",
    "    print(\"build matrices for predictions 0 ...\")\n",
    "    x_1 = polynomial_expansion(x_test_0, models[\"jet0\"][\"degree\"], mixed_columns=models[\"jet0\"][\"mixed\"])\n",
    "    print(\"build matrices for predictions 1 ...\")\n",
    "    x_2 = polynomial_expansion(x_test_1, models[\"jet1\"][\"degree\"], mixed_columns=models[\"jet1\"][\"mixed\"])\n",
    "    print(\"build matrices for predictions 2 ...\")\n",
    "    x_3 = polynomial_expansion(x_test_2, models[\"jet2\"][\"degree\"], mixed_columns=models[\"jet2\"][\"mixed\"])\n",
    "\n",
    "    print(\"compute predictions...\")\n",
    "\n",
    "    y_0_predicted = predict_labels(w_0, x_1)\n",
    "    y_1_predicted = predict_labels(w_1, x_2)\n",
    "    y_2_predicted = predict_labels(w_2, x_3)\n",
    "\n",
    "    y_pred = np.zeros((len(x_test), 1))\n",
    "    y_pred[x_test[:, i_PRI]==0] = y_0_predicted\n",
    "    y_pred[x_test[:, i_PRI]==1] = y_1_predicted\n",
    "    y_pred[x_test[:, i_PRI]>=2] = y_2_predicted\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH=\"out-check.csv\"\n",
    "y_pred = predict(models_statistics_31oct_15, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation\n",
    "Is it possible to run this code to estimate the accuracy of the given model on the test dataset without uploading a csv submission to AIcrowd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(models) : \n",
    "    \"\"\" Estimates the accuracy of our model on the test dataset without uploading to AIcrowd \"\"\"\n",
    "    i_PRI = 22\n",
    "    n_0 = sum(tX_test[:, i_PRI]==0)\n",
    "    n_1 = sum(tX_test[:, i_PRI]==1)\n",
    "    n_2 = sum(tX_test[:, i_PRI]>=2)\n",
    "\n",
    "    accuracy = (n_0*models[\"jet0\"][\"accuracy\"] + n_1*models[\"jet1\"][\"accuracy\"] + n_2*models[\"jet2\"][\"accuracy\"])/(len(tX_test))\n",
    "\n",
    "    print(\"The estimate accuracy with the given model is\", round(accuracy, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation(models_statistics_31oct_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to use this code to plot the accuracy of the hyper-parameters for a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disk_helpers import *\n",
    "from plots import *\n",
    "\n",
    "folder = \"20211031-135405-jet0-least-squares\"\n",
    "lambdas = load_np_array(folder, \"l\")\n",
    "degrees = load_np_array(folder, \"d\")\n",
    "results = load_np_array(folder, \"r\")\n",
    "plot_degree_errors_plt(degrees, lambdas, results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
