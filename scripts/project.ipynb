{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from implementations import *\n",
    "from helper import *\n",
    "from feature_analysis import *\n",
    "from expansions import polynomial_expansion\n",
    "import seaborn as sns\n",
    "import pandas as pd #temporary\n",
    "from logistic_regression import *\n",
    "import disk_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "def prepare_y_data(y,x, i_PRI=22) : \n",
    "    y_jet0  = y[x[:, i_PRI]==0]\n",
    "    y_jet1  = y[x[:, i_PRI] == 1]\n",
    "    y_jet2  = y[x[:, i_PRI] > 1]\n",
    "\n",
    "    y_jet0 = y_jet0.reshape((len(y_jet0), 1))\n",
    "    y_jet1 = y_jet1.reshape((len(y_jet1), 1))\n",
    "    y_jet2 = y_jet2.reshape((len(y_jet2), 1))\n",
    "\n",
    "    return y_jet0, y_jet1, y_jet2\n",
    "\n",
    "\n",
    "def prepare_x_data(x, i_PRI=22) : \n",
    "    tx_jet0 = x[x[:, i_PRI]==0]\n",
    "    tx_jet1 = x[x[:, i_PRI] == 1]\n",
    "    tx_jet2 = x[x[:, i_PRI] > 1]\n",
    "\n",
    "\n",
    "    tx_0_filtered = np.delete(tx_jet0, [4,5,6,12,22,23,24,25,26,27,28], axis=1)\n",
    "    tx_1_filtered = np.delete(tx_jet1, [4,5,6,12,22,26,27,28], axis=1)\n",
    "    tx_2_filtered = np.delete(tx_jet2, [22], axis=1)\n",
    "\n",
    "    tx_0_filtered = fix_nan_values(fix_missing_values(tx_0_filtered))\n",
    "    tx_1_filtered = fix_nan_values(fix_missing_values(tx_1_filtered))\n",
    "    tx_2_filtered = fix_nan_values(fix_missing_values(tx_2_filtered))\n",
    "\n",
    "    tx_0 = featureExpand(tx_0_filtered, 0)\n",
    "    tx_1 = featureExpand(tx_1_filtered, 1)\n",
    "    tx_2 = featureExpand(tx_2_filtered, 2)\n",
    "    \n",
    "    return tx_0, tx_1, tx_2\n",
    "\n",
    "def remove_outliers(y, tx, keep=0.95) : \n",
    "    values_to_be_deleted = np.zeros(tx.shape[0]) # At first we keep all\n",
    "    for column in range(tx.shape[1]) : \n",
    "        min_value = np.quantile(tx[:, column],(1-keep)/2)\n",
    "        max_value = np.quantile(tx[:, column],(1+keep)/2)\n",
    "        values_to_be_deleted = np.logical_or(values_to_be_deleted, np.logical_or(tx[:, column]<min_value, tx[:, column]>max_value))\n",
    "    \n",
    "    values_to_be_kept = np.logical_not(values_to_be_deleted)\n",
    "    return y[values_to_be_kept, :], tx[values_to_be_kept, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_0, tx_train_1, tx_train_2 = prepare_x_data(tX)\n",
    "y_0, y_1, y_2 = prepare_y_data(y, tX)\n",
    "\n",
    "y_0, tx_train_0 = remove_outliers(y_0, tx_train_0)\n",
    "y_1, tx_train_1 = remove_outliers(y_1, tx_train_1)\n",
    "y_2, tx_train_2 = remove_outliers(y_2, tx_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.DataFrame(tx_train_0)\n",
    "for column in db : \n",
    "    plt.figure()\n",
    "    db.boxplot([column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_logistic_regression_model(y, tx, max_iter=20, gamma=0.05, k_fold=3) :\n",
    "    \"\"\"Computes the best logistic regression model for the given `y` and `tx`\"\"\"\n",
    "\n",
    "    lambdas = np.logspace(-10, 4, 15)\n",
    "    degrees = np.arange(1, 7)\n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) : \n",
    "        expanded_tx = polynomial_expansion(tx, degree)\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "            results[i_degree, i_lambda] = cross_validate_logistic_regression(y, expanded_tx, max_iter, gamma, lambda_, k_fold)\n",
    "            print(\"degree={d},\\t lambda={l:e},\\taccuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "\n",
    "    disk_helpers.save_data('logistic-regression', degrees, lambdas, results)\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_logistic_regression_model(y_0, tx_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from least_squares import cross_validate_least_squares\n",
    "from plots import plot_degree_errors_plt\n",
    "\n",
    "\n",
    "def find_best_least_squares_model(y, tx, jet_string, k_fold=7) :\n",
    "    \"\"\"Computes the best least squares model for the given `y` and `tx`\"\"\"\n",
    "    lambdas = np.logspace(-4, 9, 9)\n",
    "    degrees = np.arange(2,10)\n",
    "\n",
    "    results = np.zeros((len(degrees), len(lambdas)))\n",
    "\n",
    "    for i_degree, degree in enumerate(degrees) :\n",
    "        print(\"build expanded...\")\n",
    "        expanded_tx = polynomial_expansion(tx, degree, mixed_columns=True)\n",
    "        print(\"build model...\")\n",
    "        for i_lambda, lambda_  in enumerate(lambdas) : \n",
    "            try : \n",
    "                results[i_degree, i_lambda] = cross_validate_least_squares(y, expanded_tx, lambda_, k_fold)\n",
    "                print(\"degree={d},\\t lambda={l:e},\\t accuracy={a}\".format(d=degree, l=lambda_, a=results[i_degree, i_lambda]))\n",
    "            except np.linalg.LinAlgError : \n",
    "                results[i_degree, i_lambda] = 0\n",
    "                print(\"degree={d},\\t lambda={l:e},\\t accuracy={a}\".format(d=degree, l=lambda_, a=\"0 - singular matrix\"))\n",
    "\n",
    "    i,j = np.unravel_index(np.argmax(results, axis=None), results.shape)\n",
    "    disk_helpers.save_data('least-squares', jet_string, degrees, lambdas, results)\n",
    "    plot_degree_errors_plt(degrees, lambdas, results)\n",
    "\n",
    "    return degrees[i], lambdas[j], results[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build expanded...\n",
      "build model...\n",
      "degree=2,\t lambda=1.000000e-04,\t accuracy=0.8464761904761906\n",
      "degree=2,\t lambda=4.216965e-03,\t accuracy=0.8470129870129871\n",
      "degree=2,\t lambda=1.778279e-01,\t accuracy=0.8467532467532467\n",
      "degree=2,\t lambda=7.498942e+00,\t accuracy=0.84604329004329\n",
      "degree=2,\t lambda=3.162278e+02,\t accuracy=0.8457489177489178\n",
      "degree=2,\t lambda=1.333521e+04,\t accuracy=0.8444329004329004\n",
      "degree=2,\t lambda=5.623413e+05,\t accuracy=0.842926406926407\n",
      "degree=2,\t lambda=2.371374e+07,\t accuracy=0.8413852813852812\n",
      "degree=2,\t lambda=1.000000e+09,\t accuracy=0.8363290043290043\n",
      "build expanded...\n",
      "build model...\n",
      "degree=3,\t lambda=1.000000e-04,\t accuracy=0.7826839826839828\n",
      "degree=3,\t lambda=4.216965e-03,\t accuracy=0.8472554112554113\n",
      "degree=3,\t lambda=1.778279e-01,\t accuracy=0.847047619047619\n",
      "degree=3,\t lambda=7.498942e+00,\t accuracy=0.846077922077922\n",
      "degree=3,\t lambda=3.162278e+02,\t accuracy=0.8460259740259739\n",
      "degree=3,\t lambda=1.333521e+04,\t accuracy=0.8450735930735931\n",
      "degree=3,\t lambda=5.623413e+05,\t accuracy=0.8435844155844155\n",
      "degree=3,\t lambda=2.371374e+07,\t accuracy=0.8434632034632035\n",
      "degree=3,\t lambda=1.000000e+09,\t accuracy=0.8405021645021645\n",
      "build expanded...\n",
      "build model...\n",
      "degree=4,\t lambda=1.000000e-04,\t accuracy=0.7842770562770564\n",
      "degree=4,\t lambda=4.216965e-03,\t accuracy=0.8317402597402597\n",
      "degree=4,\t lambda=1.778279e-01,\t accuracy=0.7671515151515151\n",
      "degree=4,\t lambda=7.498942e+00,\t accuracy=0.8167099567099567\n",
      "degree=4,\t lambda=3.162278e+02,\t accuracy=0.8462857142857143\n",
      "degree=4,\t lambda=1.333521e+04,\t accuracy=0.8459567099567099\n",
      "degree=4,\t lambda=5.623413e+05,\t accuracy=0.8452467532467534\n",
      "degree=4,\t lambda=2.371374e+07,\t accuracy=0.8443982683982684\n",
      "degree=4,\t lambda=1.000000e+09,\t accuracy=0.8426839826839828\n",
      "build expanded...\n",
      "build model...\n",
      "degree=5,\t lambda=1.000000e-04,\t accuracy=0.8447272727272728\n",
      "degree=5,\t lambda=4.216965e-03,\t accuracy=0.8253160173160173\n",
      "degree=5,\t lambda=1.778279e-01,\t accuracy=0.8458528138528137\n",
      "degree=5,\t lambda=7.498942e+00,\t accuracy=0.843064935064935\n",
      "degree=5,\t lambda=3.162278e+02,\t accuracy=0.7849523809523811\n",
      "degree=5,\t lambda=1.333521e+04,\t accuracy=0.8304242424242423\n",
      "degree=5,\t lambda=5.623413e+05,\t accuracy=0.8457835497835499\n",
      "degree=5,\t lambda=2.371374e+07,\t accuracy=0.8445541125541125\n",
      "degree=5,\t lambda=1.000000e+09,\t accuracy=0.844\n",
      "build expanded...\n",
      "build model...\n",
      "degree=6,\t lambda=1.000000e-04,\t accuracy=0.8472727272727274\n",
      "degree=6,\t lambda=4.216965e-03,\t accuracy=0.8458354978354979\n",
      "degree=6,\t lambda=1.778279e-01,\t accuracy=0.8392380952380952\n",
      "degree=6,\t lambda=7.498942e+00,\t accuracy=0.8244155844155844\n",
      "degree=6,\t lambda=3.162278e+02,\t accuracy=0.7944242424242424\n",
      "degree=6,\t lambda=1.333521e+04,\t accuracy=0.8441038961038959\n",
      "degree=6,\t lambda=5.623413e+05,\t accuracy=0.8437922077922079\n",
      "degree=6,\t lambda=2.371374e+07,\t accuracy=0.7683463203463202\n",
      "degree=6,\t lambda=1.000000e+09,\t accuracy=0.7825627705627705\n",
      "build expanded...\n",
      "build model...\n",
      "degree=7,\t lambda=1.000000e-04,\t accuracy=0.8471515151515152\n",
      "degree=7,\t lambda=4.216965e-03,\t accuracy=0.846060606060606\n",
      "degree=7,\t lambda=1.778279e-01,\t accuracy=0.8441558441558442\n",
      "degree=7,\t lambda=7.498942e+00,\t accuracy=0.8058874458874458\n",
      "degree=7,\t lambda=3.162278e+02,\t accuracy=0.8167272727272727\n",
      "degree=7,\t lambda=1.333521e+04,\t accuracy=0.733939393939394\n",
      "degree=7,\t lambda=5.623413e+05,\t accuracy=0.715930735930736\n",
      "degree=7,\t lambda=2.371374e+07,\t accuracy=0.8003290043290043\n",
      "degree=7,\t lambda=1.000000e+09,\t accuracy=0.8433939393939394\n",
      "build expanded...\n",
      "build model...\n",
      "degree=8,\t lambda=1.000000e-04,\t accuracy=0.8119826839826839\n",
      "degree=8,\t lambda=4.216965e-03,\t accuracy=0.8461125541125541\n",
      "degree=8,\t lambda=1.778279e-01,\t accuracy=0.8322251082251083\n",
      "degree=8,\t lambda=7.498942e+00,\t accuracy=0.7537142857142857\n",
      "degree=8,\t lambda=3.162278e+02,\t accuracy=0.824969696969697\n",
      "degree=8,\t lambda=1.333521e+04,\t accuracy=0.8414545454545455\n",
      "degree=8,\t lambda=5.623413e+05,\t accuracy=0.7643809523809525\n",
      "degree=8,\t lambda=2.371374e+07,\t accuracy=0.8172813852813853\n",
      "degree=8,\t lambda=1.000000e+09,\t accuracy=0.7872380952380952\n",
      "build expanded...\n",
      "build model...\n",
      "degree=9,\t lambda=1.000000e-04,\t accuracy=0.8470649350649351\n",
      "degree=9,\t lambda=4.216965e-03,\t accuracy=0.8426147186147185\n",
      "degree=9,\t lambda=1.778279e-01,\t accuracy=0.8092121212121212\n",
      "degree=9,\t lambda=7.498942e+00,\t accuracy=0.7842770562770564\n",
      "degree=9,\t lambda=3.162278e+02,\t accuracy=0.8446406926406925\n",
      "degree=9,\t lambda=1.333521e+04,\t accuracy=0.8225627705627707\n",
      "degree=9,\t lambda=5.623413e+05,\t accuracy=0.7966060606060605\n",
      "degree=9,\t lambda=2.371374e+07,\t accuracy=0.8123463203463203\n",
      "degree=9,\t lambda=1.000000e+09,\t accuracy=0.7957056277056277\n",
      "build expanded...\n",
      "build model...\n",
      "degree=2,\t lambda=1.000000e-04,\t accuracy=0.7946210877245361\n",
      "degree=2,\t lambda=4.216965e-03,\t accuracy=0.7943722943722944\n",
      "degree=2,\t lambda=1.778279e-01,\t accuracy=0.7954421057869334\n",
      "degree=2,\t lambda=7.498942e+00,\t accuracy=0.7956660198039508\n",
      "degree=2,\t lambda=3.162278e+02,\t accuracy=0.7941483803552768\n",
      "degree=2,\t lambda=1.333521e+04,\t accuracy=0.792506344230482\n",
      "degree=2,\t lambda=5.623413e+05,\t accuracy=0.789719858685376\n",
      "degree=2,\t lambda=2.371374e+07,\t accuracy=0.7823555754590237\n",
      "degree=2,\t lambda=1.000000e+09,\t accuracy=0.7634472806886601\n",
      "build expanded...\n",
      "build model...\n",
      "degree=3,\t lambda=1.000000e-04,\t accuracy=0.6747773299497437\n",
      "degree=3,\t lambda=4.216965e-03,\t accuracy=0.7951186744290192\n",
      "degree=3,\t lambda=1.778279e-01,\t accuracy=0.7959396924914167\n",
      "degree=3,\t lambda=7.498942e+00,\t accuracy=0.7959148131561925\n",
      "degree=3,\t lambda=3.162278e+02,\t accuracy=0.7956660198039509\n",
      "degree=3,\t lambda=1.333521e+04,\t accuracy=0.7953923471164851\n",
      "degree=3,\t lambda=5.623413e+05,\t accuracy=0.7939244663382594\n",
      "degree=3,\t lambda=2.371374e+07,\t accuracy=0.7861621137483207\n",
      "degree=3,\t lambda=1.000000e+09,\t accuracy=0.7796188485843659\n",
      "build expanded...\n",
      "build model...\n",
      "degree=4,\t lambda=1.000000e-04,\t accuracy=0.6704732049559635\n",
      "degree=4,\t lambda=4.216965e-03,\t accuracy=0.6590038314176245\n",
      "degree=4,\t lambda=1.778279e-01,\t accuracy=0.7056277056277057\n",
      "degree=4,\t lambda=7.498942e+00,\t accuracy=0.6924914166293477\n",
      "degree=4,\t lambda=3.162278e+02,\t accuracy=0.7972582972582972\n",
      "degree=4,\t lambda=1.333521e+04,\t accuracy=0.7972334179230731\n",
      "degree=4,\t lambda=5.623413e+05,\t accuracy=0.7964870378663482\n",
      "degree=4,\t lambda=2.371374e+07,\t accuracy=0.7904164800716524\n",
      "degree=4,\t lambda=1.000000e+09,\t accuracy=0.7869582524754939\n",
      "build expanded...\n",
      "build model...\n",
      "degree=5,\t lambda=1.000000e-04,\t accuracy=0.765114196148679\n",
      "degree=5,\t lambda=4.216965e-03,\t accuracy=0.6155645121162363\n",
      "degree=5,\t lambda=1.778279e-01,\t accuracy=0.6356172563069115\n",
      "degree=5,\t lambda=7.498942e+00,\t accuracy=0.6192466537294125\n",
      "degree=5,\t lambda=3.162278e+02,\t accuracy=0.7236901030004478\n",
      "degree=5,\t lambda=1.333521e+04,\t accuracy=0.6435537642434195\n",
      "degree=5,\t lambda=5.623413e+05,\t accuracy=0.6179031696273075\n",
      "degree=5,\t lambda=2.371374e+07,\t accuracy=0.7958152958152959\n",
      "degree=5,\t lambda=1.000000e+09,\t accuracy=0.7926058615713788\n",
      "build expanded...\n",
      "build model...\n",
      "degree=6,\t lambda=1.000000e-04,\t accuracy=0.7920336368612232\n",
      "degree=6,\t lambda=4.216965e-03,\t accuracy=0.6942578494302633\n",
      "degree=6,\t lambda=1.778279e-01,\t accuracy=0.6203164651440513\n",
      "degree=6,\t lambda=7.498942e+00,\t accuracy=0.6433049708911778\n",
      "degree=6,\t lambda=3.162278e+02,\t accuracy=0.5524456386525352\n",
      "degree=6,\t lambda=1.333521e+04,\t accuracy=0.6099666616907996\n",
      "degree=6,\t lambda=5.623413e+05,\t accuracy=0.6461660944419565\n",
      "degree=6,\t lambda=2.371374e+07,\t accuracy=0.6816689058068368\n",
      "degree=6,\t lambda=1.000000e+09,\t accuracy=0.7552371000646863\n",
      "build expanded...\n",
      "build model...\n",
      "degree=7,\t lambda=1.000000e-04,\t accuracy=0.7453102453102453\n",
      "degree=7,\t lambda=4.216965e-03,\t accuracy=0.7718067373239786\n",
      "degree=7,\t lambda=1.778279e-01,\t accuracy=0.6110115937702144\n",
      "degree=7,\t lambda=7.498942e+00,\t accuracy=0.6712195850126885\n",
      "degree=7,\t lambda=3.162278e+02,\t accuracy=0.6832611832611832\n",
      "degree=7,\t lambda=1.333521e+04,\t accuracy=0.5788177339901478\n",
      "degree=7,\t lambda=5.623413e+05,\t accuracy=0.5643379608896851\n",
      "degree=7,\t lambda=2.371374e+07,\t accuracy=0.6219585012688461\n",
      "degree=7,\t lambda=1.000000e+09,\t accuracy=0.5939692491416629\n",
      "build expanded...\n",
      "build model...\n",
      "degree=8,\t lambda=1.000000e-04,\t accuracy=0.7913867741453948\n",
      "degree=8,\t lambda=4.216965e-03,\t accuracy=0.7486938349007314\n",
      "degree=8,\t lambda=1.778279e-01,\t accuracy=0.728616211374832\n",
      "degree=8,\t lambda=7.498942e+00,\t accuracy=0.7197094093645818\n",
      "degree=8,\t lambda=3.162278e+02,\t accuracy=0.6300940438871473\n",
      "degree=8,\t lambda=1.333521e+04,\t accuracy=0.6286510424441458\n",
      "degree=8,\t lambda=5.623413e+05,\t accuracy=0.6692789968652038\n",
      "degree=8,\t lambda=2.371374e+07,\t accuracy=0.6589540727471761\n",
      "degree=8,\t lambda=1.000000e+09,\t accuracy=0.5495845151017564\n",
      "build expanded...\n",
      "build model...\n",
      "degree=9,\t lambda=1.000000e-04,\t accuracy=0.7869084938050455\n",
      "degree=9,\t lambda=4.216965e-03,\t accuracy=0.7792954172264517\n",
      "degree=9,\t lambda=1.778279e-01,\t accuracy=0.7564810668258944\n",
      "degree=9,\t lambda=7.498942e+00,\t accuracy=0.7927053789122754\n",
      "degree=9,\t lambda=3.162278e+02,\t accuracy=0.7914862914862916\n",
      "degree=9,\t lambda=1.333521e+04,\t accuracy=0.7687465790914068\n",
      "degree=9,\t lambda=5.623413e+05,\t accuracy=0.7238393790117928\n",
      "degree=9,\t lambda=2.371374e+07,\t accuracy=0.7693685624720109\n",
      "degree=9,\t lambda=1.000000e+09,\t accuracy=0.741603224361845\n",
      "build expanded...\n",
      "build model...\n",
      "degree=2,\t lambda=1.000000e-04,\t accuracy=0 - singular matrix\n",
      "degree=2,\t lambda=4.216965e-03,\t accuracy=0.8302235830702006\n",
      "degree=2,\t lambda=1.778279e-01,\t accuracy=0.8302235830702006\n",
      "degree=2,\t lambda=7.498942e+00,\t accuracy=0.8296175804548209\n",
      "degree=2,\t lambda=3.162278e+02,\t accuracy=0.8289158932159603\n",
      "degree=2,\t lambda=1.333521e+04,\t accuracy=0.8285331547220361\n",
      "degree=2,\t lambda=5.623413e+05,\t accuracy=0.8247057697827959\n",
      "degree=2,\t lambda=2.371374e+07,\t accuracy=0.8195388001148215\n",
      "degree=2,\t lambda=1.000000e+09,\t accuracy=0.8087264376614678\n",
      "build expanded...\n",
      "build model...\n",
      "degree=3,\t lambda=1.000000e-04,\t accuracy=0 - singular matrix\n",
      "degree=3,\t lambda=4.216965e-03,\t accuracy=0.7492424967307754\n",
      "degree=3,\t lambda=1.778279e-01,\t accuracy=0.7459573246579273\n",
      "degree=3,\t lambda=7.498942e+00,\t accuracy=0.6599049532740089\n",
      "degree=3,\t lambda=3.162278e+02,\t accuracy=0.7333907441074219\n",
      "degree=3,\t lambda=1.333521e+04,\t accuracy=0.8297451599527956\n",
      "degree=3,\t lambda=5.623413e+05,\t accuracy=0.8287245239689981\n",
      "degree=3,\t lambda=2.371374e+07,\t accuracy=0.8254393518961504\n",
      "degree=3,\t lambda=1.000000e+09,\t accuracy=0.8152010971836824\n",
      "build expanded...\n",
      "build model...\n",
      "degree=4,\t lambda=1.000000e-04,\t accuracy=0.46955634229579296\n",
      "degree=4,\t lambda=4.216965e-03,\t accuracy=0.79309794915957\n",
      "degree=4,\t lambda=1.778279e-01,\t accuracy=0.7903230950786208\n",
      "degree=4,\t lambda=7.498942e+00,\t accuracy=0.8149459381877332\n",
      "degree=4,\t lambda=3.162278e+02,\t accuracy=0.8110547634995057\n",
      "degree=4,\t lambda=1.333521e+04,\t accuracy=0.6918955123911587\n",
      "degree=4,\t lambda=5.623413e+05,\t accuracy=0.6867285427231844\n",
      "degree=4,\t lambda=2.371374e+07,\t accuracy=0.8144675150703282\n",
      "degree=4,\t lambda=1.000000e+09,\t accuracy=0.7750454501961535\n",
      "build expanded...\n",
      "build model...\n",
      "degree=5,\t lambda=1.000000e-04,\t accuracy=0.4781041686600963\n",
      "degree=5,\t lambda=4.216965e-03,\t accuracy=0.7878671897426085\n",
      "degree=5,\t lambda=1.778279e-01,\t accuracy=0.7095652728606513\n",
      "degree=5,\t lambda=7.498942e+00,\t accuracy=0.7255446049819794\n",
      "degree=5,\t lambda=3.162278e+02,\t accuracy=0.7804356839855835\n",
      "degree=5,\t lambda=1.333521e+04,\t accuracy=0.7385896086498899\n",
      "degree=5,\t lambda=5.623413e+05,\t accuracy=0.7945013236372914\n",
      "degree=5,\t lambda=2.371374e+07,\t accuracy=0.8308295856855804\n",
      "degree=5,\t lambda=1.000000e+09,\t accuracy=0.8277357828596944\n",
      "build expanded...\n",
      "build model...\n",
      "degree=6,\t lambda=1.000000e-04,\t accuracy=0 - singular matrix\n",
      "degree=6,\t lambda=4.216965e-03,\t accuracy=0.7595764360667241\n",
      "degree=6,\t lambda=1.778279e-01,\t accuracy=0.790705833572545\n",
      "degree=6,\t lambda=7.498942e+00,\t accuracy=0.7339329569738143\n",
      "degree=6,\t lambda=3.162278e+02,\t accuracy=0.7100755908525499\n",
      "degree=6,\t lambda=1.333521e+04,\t accuracy=0.7362612828118521\n",
      "degree=6,\t lambda=5.623413e+05,\t accuracy=0.7063438905367907\n",
      "degree=6,\t lambda=2.371374e+07,\t accuracy=0.7954581698721015\n",
      "degree=6,\t lambda=1.000000e+09,\t accuracy=0.8291710522119095\n",
      "build expanded...\n",
      "build model...\n",
      "degree=7,\t lambda=1.000000e-04,\t accuracy=0.4813574458584506\n",
      "degree=7,\t lambda=4.216965e-03,\t accuracy=0.8277038879852008\n",
      "degree=7,\t lambda=1.778279e-01,\t accuracy=0.7277453513220424\n",
      "degree=7,\t lambda=7.498942e+00,\t accuracy=0.7278410359455236\n",
      "degree=7,\t lambda=3.162278e+02,\t accuracy=0.7331036902369789\n",
      "degree=7,\t lambda=1.333521e+04,\t accuracy=0.7368991803017255\n",
      "degree=7,\t lambda=5.623413e+05,\t accuracy=0.8300003189487449\n",
      "degree=7,\t lambda=2.371374e+07,\t accuracy=0.7761617708034318\n"
     ]
    }
   ],
   "source": [
    "find_best_least_squares_model(y_0, tx_train_0, 'jet0')\n",
    "find_best_least_squares_model(y_1, tx_train_1, 'jet1')\n",
    "find_best_least_squares_model(y_2, tx_train_2, 'jet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(y, tx) : \n",
    "    \"\"\"Finds the best model for the given `y` and `tx`\"\"\"\n",
    "    degree_logistic, lambda_logistic, acc_logistic = find_best_logistic_regression_model(y, tx)\n",
    "    print(\"Logistic regression: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_logistic, l=lambda_logistic, a=acc_logistic))\n",
    "    degree_ls, lambda_ls, acc_ls = find_best_least_squares_model(y, tx)\n",
    "    print(\"Least squares: (degree: {d}, lambda: {l}, accuracy: {a})\".format(d=degree_ls, l=lambda_ls, a=acc_ls))\n",
    "\n",
    "    if acc_logistic > acc_ls : \n",
    "        return \"logistic regression\", degree_logistic, lambda_logistic, acc_logistic\n",
    "    else : \n",
    "        return \"least squares\", degree_ls, lambda_ls, acc_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_for_higgs_dataset() : \n",
    "    \"\"\"Finds the best model for the entire train dataset\"\"\"\n",
    "    \n",
    "    jet_0_model, jet_0_degree, jet_0_lambda, jet_0_accuracy = find_best_model(y_0, tx_train_0)\n",
    "    print(\"Jet0: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_0_model,d=jet_0_degree,l=jet_0_lambda,a=jet_0_accuracy))\n",
    "    jet_1_model, jet_1_degree, jet_1_lambda, jet_1_accuracy = find_best_model(y_1, tx_train_1)\n",
    "    print(\"Jet1: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_1_model,d=jet_1_degree,l=jet_1_lambda,a=jet_1_accuracy))\n",
    "    jet_2_model, jet_2_degree, jet_2_lambda, jet_2_accuracy = find_best_model(y_2, tx_train_2)\n",
    "    print(\"Jet2: model={m}, degree={d}, lambda={l}, accuracy={a}\".format(m=jet_2_model,d=jet_2_degree,l=jet_2_lambda,a=jet_2_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_model_for_higgs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 5,\n",
    "        \"lambda\" : 1e-3,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-6,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.7976 # tx not mixed\n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 6,\n",
    "        \"lambda\" : 1e-4,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0\n",
    "    }\n",
    "}\n",
    "\n",
    "models_new = {\n",
    "    \"jet0\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 3,\n",
    "        \"lambda\" : 0.1,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8355219697727956\n",
    "    },\n",
    "    \"jet1\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 7,\n",
    "        \"lambda\" : 1e-5,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8043203507866906  \n",
    "    },\n",
    "    \"jet2\" : {\n",
    "        \"model\" : \"least squares\",\n",
    "        \"degree\" : 5,\n",
    "        \"lambda\" : 0.001,\n",
    "        \"mixed\" : False,\n",
    "        \"accuracy\" : 0.8258478081058727 \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(models) : \n",
    "    \"\"\"Computes the weights for the given models\"\"\"\n",
    "    weights = []\n",
    "    y = [y_0, y_1, y_2]  \n",
    "    tx = [tx_train_0, tx_train_1, tx_train_2]\n",
    "    for i, (jet, model) in enumerate(models.items()) : \n",
    "        x_expanded = polynomial_expansion(tx[i], model[\"degree\"], model[\"mixed\"])\n",
    "        if model[\"model\"] == \"least squares\" : \n",
    "            w, err = ridge_regression(y[i], x_expanded, model[\"lambda\"])\n",
    "            weights.append(w)\n",
    "        elif model[\"model\"] == \"logistic regression\" : \n",
    "            w = logistic_regression_penalized_gradient_descent(y[i], x_expanded, 0.01, model[\"lambda\"], 30)\n",
    "            weights.append(w)\n",
    "        else : \n",
    "            raise Exception(\"Model not recognised\")\n",
    "        print(\"weights computed for\", jet)\n",
    "            \n",
    "    return weights[0], weights[1], weights[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, x_test) : \n",
    "    \"\"\"Makes the prediction given the models chosen and the test dataset\"\"\"\n",
    "    i_PRI = 22\n",
    "    print(\"prepare dataset...\")\n",
    "    x_test_0, x_test_1, x_test_2 = prepare_x_data(x_test)\n",
    "    print(\"compute weights...\")\n",
    "    w_0, w_1, w_2 = compute_weights(models)\n",
    "    print(\"compute predictions...\")\n",
    "    x_test_0 = polynomial_expansion(x_test_0, models[\"jet0\"][\"degree\"])\n",
    "    x_test_1 = polynomial_expansion(x_test_1, models[\"jet1\"][\"degree\"])\n",
    "    x_test_2 = polynomial_expansion(x_test_2, models[\"jet2\"][\"degree\"])\n",
    "\n",
    "    y_0_predicted = predict_labels(w_0, x_test_0)\n",
    "    y_1_predicted = predict_labels(w_1, x_test_1)\n",
    "    y_2_predicted = predict_labels(w_2, x_test_2)\n",
    "\n",
    "    y_pred = np.zeros((len(x_test), 1))\n",
    "    y_pred[x_test[:, i_PRI]==0] = y_0_predicted\n",
    "    y_pred[x_test[:, i_PRI]==1] = y_1_predicted\n",
    "    y_pred[x_test[:, i_PRI]>=2] = y_2_predicted\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH=\"out3.csv\"\n",
    "y_pred = predict(models_new, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation\n",
    "We can estimate the accuracy of our model on the test dataset without uploading data su AIcrowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(models) : \n",
    "    \"\"\" Estimates the accuracy of our model on the test dataset without uploading to AIcrowd \"\"\"\n",
    "    i_PRI = 22\n",
    "    n_0 = sum(tX_test[:, i_PRI]==0)\n",
    "    n_1 = sum(tX_test[:, i_PRI]==1)\n",
    "    n_2 = sum(tX_test[:, i_PRI]>=2)\n",
    "\n",
    "    accuracy = (n_0*models[\"jet0\"][\"accuracy\"] + n_1*models[\"jet1\"][\"accuracy\"] + n_2*models[\"jet2\"][\"accuracy\"])/(len(tX_test))\n",
    "\n",
    "    print(\"The estimate accuracy with the given model is\", round(accuracy, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation(models_new)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "047d5c4a70aa4e5ae964d8b25b83a0a6056fc4ba4dd2c3a708bdfa354f913a43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}